{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaussssss/machinelearning-tpe/blob/main/Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me-3ZAmhGvSC",
        "outputId": "8871f9e3-71a1-400b-8b96-14d9d2914c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "importations des packages python nécessaires\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import scipy.stats as sps\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/random_forest/\"\n",
        "dataset = pd.read_csv(data_path+'agaricus-lepiota.data',header=None)\n",
        "dataset = dataset.sample(frac=1)\n",
        "dataset.columns = ['target','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing',\n",
        "'gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring',\n",
        "'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population',\n",
        "'habitat']\n",
        "##################################################################\n",
        "#########################################\n",
        "##################################################################\n",
        "#########################################\n",
        "def entropy(target_col):\n",
        "  elements,counts = np.unique(target_col,return_counts = True)\n",
        "  entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
        "  return entropy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE2w_VZdHVow"
      },
      "outputs": [],
      "source": [
        "def InfoGain(data,split_attribute_name,target_name=\"target\"):\n",
        "  #Calculer l'entropie de l'ensemble de données total\n",
        "  total_entropy = entropy(data[target_name])\n",
        "  ##Calculer l'entropie du jeu de données\n",
        "  #Calculer les valeurs et les décomptes correspondants pour l'attribut split\n",
        "  vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
        "  #Calculer l'entropie pondérée\n",
        "  Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) \n",
        "  for i in range(len(vals))])\n",
        "  #Calculer le gain d'information\n",
        "  Information_Gain = total_entropy - Weighted_Entropy\n",
        "  return Information_Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbOQGk1oHo2v"
      },
      "outputs": [],
      "source": [
        "def ID3(data,originaldata,features,target_attribute_name=\"target\",parent_node_class = None):\n",
        "  #Définissez les critères d'arrêt --> Si l'un de ces critères est satisfait, nous voulons renvoyer un nœud feuille #\n",
        "  #Si toutes les valeurs_cibles ont la même valeur, renvoie cette valeur\n",
        "  if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "    return np.unique(data[target_attribute_name])[0]\n",
        "    #Si l'ensemble de données est vide, renvoie la valeur de l'entité cible du mode dans l'ensemble de données d'origine\n",
        "  elif len(data)==0:\n",
        "    return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],\n",
        "                                                                              return_counts=True)[1])]\n",
        "  #Si l'espace de fonctions est vide, renvoyez la valeur de la fonction cible du mode du nœud parent direct --> Notez que\n",
        "   #le nœud parent direct est le nœud qui a appelé l'exécution actuelle de l'algorithme ID3 et donc\n",
        "   #la valeur de la caractéristique cible du mode est stockée dans la variable parent_node_class.\n",
        "  elif len(features) ==0:\n",
        "    return parent_node_class\n",
        "  #Si rien de ce qui précède n'est vrai, faites pousser l'arbre!\n",
        "  else:\n",
        "  #Définir la valeur par défaut pour ce nœud --> La valeur de la fonction cible du mode du nœud actuel\n",
        "    parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
        "    #unique_counts ndarray, facultatif :Le nombre de fois où chacune des valeurs uniques apparaît dans le tableau d'origine.\n",
        "    ##################################################################\n",
        "  ##############################################\n",
        "  ############!!!!!!!!!Mettre en œuvre l'échantillonnage de sous-espace. Dessinez un certain nombre d'entités m = sqrt(p)!!!!!!!!#############\n",
        "  ##################################################################\n",
        "  #############################################\n",
        "  features = np.random.choice(features,size=np.int(np.sqrt(len(features))),replace=False)\n",
        "  #Sélectionnez l'entité qui divise le mieux l'ensemble de données\n",
        "  item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Renvoie les valeurs de gain d'informations pour les entités du jeu de données\n",
        "  best_feature_index = np.argmax(item_values)\n",
        "  best_feature = features[best_feature_index]\n",
        "  #Créer l'arborescence. La racine obtient le nom de la fonctionnalité (best_feature) avec le maximum d'informations\n",
        "  #gain à la première manche\n",
        "  tree = {best_feature:{}}\n",
        "  #Supprimer la fonctionnalité avec le meilleur gain d'informations de l'espace des fonctionnalités\n",
        "  features = [i for i in features if i != best_feature]\n",
        "  #Développez une branche sous le nœud racine pour chaque valeur possible de la fonctionnalité du nœud racine\n",
        "  for value in np.unique(data[best_feature]):\n",
        "    value = value\n",
        "    #Divisez le jeu de données le long de la valeur de l'entité avec le plus grand gain d'informations et créez ainsi des sous-ensembles de données\n",
        "    sub_data = data.where(data[best_feature] == value).dropna()\n",
        "    #Appelez l'algorithme ID3 pour chacun de ces sous-ensembles de données avec les nouveaux paramètres --> Ici, la récursivité entre en jeu !\n",
        "    subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
        "    #Ajoutez le sous-arbre, développé à partir du sous-ensemble de données à l'arbre sous le nœud racine\n",
        "    tree[best_feature][value] = subtree\n",
        "  return(tree)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcsEJTddI0j_"
      },
      "outputs": [],
      "source": [
        "def predict(query,tree,default = 'p'):\n",
        "  for key in list(query.keys()):\n",
        "    if key in list(tree.keys()):\n",
        "      try:\n",
        "        result = tree[key][query[key]]\n",
        "      except:\n",
        "        return default\n",
        "      result = tree[key][query[key]]\n",
        "      if isinstance(result,dict):\n",
        "        return predict(query,result)\n",
        "      else:\n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubHoEaNrJFZh"
      },
      "outputs": [],
      "source": [
        "##################################################################\n",
        "#########################################\n",
        "##################################################################\n",
        "#########################################\n",
        "def train_test_split(dataset):\n",
        "  training_data = dataset.iloc[:round(0.75*len(dataset))].reset_index(drop=True)\n",
        "  #Nous supprimons l'index respectivement renommons l'index\n",
        "   #starting form 0, car nous ne voulons pas rencontrer d'erreurs concernant les étiquettes / index des lignes\n",
        "  testing_data = dataset.iloc[round(0.75*len(dataset)):].reset_index(drop=True)\n",
        "  return training_data,testing_data\n",
        "training_data = train_test_split(dataset)[0]\n",
        "testing_data = train_test_split(dataset)[1]\n",
        "##################################################################\n",
        "#########################################\n",
        "##################################################################\n",
        "#########################################\n",
        "#######Entraîner le modèle Random Forest###########\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPtfyPTYJZFn",
        "outputId": "d0bdf8a1-34ff-404b-dab6-ca740aeb2b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target:  e\n",
            "prediction:  e\n"
          ]
        }
      ],
      "source": [
        "def RandomForest_Train(dataset,number_of_Trees):\n",
        "  #Créer une liste dans laquelle les forêts individuelles sont stockées\n",
        "  random_forest_sub_tree = []\n",
        "  #Créer un certain nombre de n modèles\n",
        "  for i in range(number_of_Trees):\n",
        "    #Créer un certain nombre d'ensembles de données échantillonnés bootstrap à partir de l'ensemble de données d'origine\n",
        "    bootstrap_sample = dataset.sample(frac=1,replace=True)\n",
        "    #Créez un ensemble de données d'entraînement et de test en appelant la fonction train_test_split\n",
        "    bootstrap_training_data = train_test_split(bootstrap_sample)[0]\n",
        "    bootstrap_testing_data = train_test_split(bootstrap_sample)[1]\n",
        "    #Développez un modèle d'arbre pour chacune des données d'apprentissage\n",
        "    #Nous implémentons l'échantillonnage de sous-espace dans l'algorithme ID3 lui-même. Jetez donc un œil à l'algorithme ID3 ci-dessus !\n",
        "    random_forest_sub_tree.append(ID3(bootstrap_training_data,bootstrap_training_data,\n",
        "                      bootstrap_training_data.drop(labels=['target'],axis=1).columns))\n",
        "  return random_forest_sub_tree\n",
        "random_forest = RandomForest_Train(dataset,50)\n",
        "#######Prédire une nouvelle instance de requête###########\n",
        "def RandomForest_Predict(query,random_forest,default='p'):\n",
        "  predictions = []\n",
        "  for tree in random_forest:\n",
        "    predictions.append(predict(query,tree,default))\n",
        "  return sps.mode(predictions)[0][0]\n",
        "query = testing_data.iloc[0,:].drop('target').to_dict()\n",
        "query_target = testing_data.iloc[0,0]\n",
        "print('target: ',query_target)\n",
        "prediction = RandomForest_Predict(query,random_forest)\n",
        "\n",
        "print('prediction: ',prediction)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dALP6bDXKK3B",
        "outputId": "af7ed8a5-96b1-4cb4-e620-e1444369daf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.2358444116199"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#######Testez le modèle sur les données de test et renvoyez la précision###########\n",
        "def RandomForest_Test(data,random_forest):\n",
        "  data['predictions'] = None\n",
        "  for i in range(len(data)):\n",
        "    query = data.iloc[i,:].drop('target').to_dict()\n",
        "    data.loc[i,'predictions'] = RandomForest_Predict(query,random_forest,default='p')\n",
        "  accuracy = sum(data['predictions'] == data['target'])/len(data)*100\n",
        "  #print('The prediction accuracy is: ',sum(data['predictions']== data['target'])/len(data)*100,'%')\n",
        "  return accuracy\n",
        "RandomForest_Test(testing_data,random_forest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX8QNBuzKmjw",
        "outputId": "6fb26726-12b3-4622-fadc-56e70d4a1645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "##################################################################\n",
        "############################################\n",
        "##########Tracer la précision de la prédiction par rapport au nombre d'arbres dans les forêts aléatoires#############\n",
        "##################################################################\n",
        "############################################\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "style.use('fivethirtyeight')\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "ax0 = fig.add_subplot(111)\n",
        "accuracy = []\n",
        "for i in range(1,11,1):\n",
        "  random_forest = RandomForest_Train(dataset,i)\n",
        "  accuracy.append(RandomForest_Test(testing_data,random_forest))\n",
        "for i in range(10,110,10):\n",
        "  random_forest = RandomForest_Train(dataset,i)\n",
        "  accuracy.append(RandomForest_Test(testing_data,random_forest))\n",
        "for i in range(100,1100,100):\n",
        "  random_forest = RandomForest_Train(dataset,i)\n",
        "  accuracy.append(RandomForest_Test(testing_data,random_forest))\n",
        "print(accuracy)\n",
        "ax0.plot(np.logspace(0,3,30),accuracy)\n",
        "ax0.set_yticks(np.linspace(50,100,50))\n",
        "ax0.set_title(\"Accuracy with respect to the numer of trees in the random forest\")\n",
        "ax0.set_xscale('log')\n",
        "ax0.set_xlabel(\"Number of Trees\")\n",
        "ax0.set_ylabel('Accuracy(%)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwxKrEMhK4Zv"
      },
      "source": [
        "#implémentation du random forests avec la librairie sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFq0mJ1sLDq5",
        "outputId": "2c1719ad-91d5-44be-9fb0-b1c43c753c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy is:  100.0 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_validate\n",
        "#Encode the feature values which are strings to integers\n",
        "for label in dataset.columns:\n",
        "  dataset[label] = LabelEncoder().fit(dataset[label]).transform(dataset[label])\n",
        "X = dataset.drop(['target'],axis=1)\n",
        "Y = dataset['target']\n",
        "#Instantiate the model with 100 trees and entropy as splitting criteria\n",
        "Random_Forest_model = RandomForestClassifier(n_estimators=100,criterion=\"entropy\")\n",
        "#Cross validation\n",
        "accuracy = cross_validate(Random_Forest_model,X,Y,cv=10)['test_score']\n",
        "print('The accuracy is: ',sum(accuracy)/len(accuracy)*100,'%')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Random_Forests.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}